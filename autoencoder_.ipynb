{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터 읽기\n",
        "TRAIN_FILES = sorted([x for x in Path(\"/content/drive/MyDrive/Colab Notebooks/train/\").glob(\"*.csv\")])\n",
        "TEST_FILES = sorted([x for x in Path(\"/content/drive/MyDrive/Colab Notebooks/test/\").glob(\"*.csv\")])\n",
        "\n",
        "def dataframe_from_csv(target):\n",
        "    return pd.read_csv(target).rename(columns=lambda x: x.strip())\n",
        "\n",
        "def dataframe_from_csvs(targets):\n",
        "    return pd.concat([dataframe_from_csv(x) for x in targets])\n",
        "\n",
        "TRAIN_DF_RAW = dataframe_from_csvs(TRAIN_FILES)\n",
        "TEST_DF_RAW = dataframe_from_csvs(TEST_FILES)\n",
        "\n",
        "# 공격 레이블 제거\n",
        "ATTACK_DF = TEST_DF_RAW['attack']\n",
        "DROP_FIELD = [\"time\", \"attack_P1\", \"attack_P2\", \"attack_P3\", \"attack\"]\n",
        "VALID_COLUMNS_IN_TRAIN_DATASET = TRAIN_DF_RAW.columns.drop(DROP_FIELD)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "TRAIN_DF = scaler.fit_transform(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET])\n",
        "TEST_DF = scaler.transform(TEST_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET])\n",
        "\n",
        "# 슬라이딩 윈도우 함수 정의\n",
        "def create_sliding_windows(data, window_size):\n",
        "    windows = []\n",
        "    for i in range(len(data) - window_size + 1):\n",
        "        windows.append(data[i:i + window_size])\n",
        "    return np.array(windows)\n",
        "\n",
        "# 윈도우 크기 설정\n",
        "window_size = 50\n",
        "\n",
        "# 슬라이딩 윈도우 적용\n",
        "TRAIN_WINDOWS = create_sliding_windows(TRAIN_DF, window_size)\n",
        "TEST_WINDOWS = create_sliding_windows(TEST_DF, window_size)\n",
        "\n",
        "# 오토인코더 모델 정의\n",
        "input_dim = TRAIN_WINDOWS.shape[1] * TRAIN_WINDOWS.shape[2]\n",
        "hidden_dim_1 = 128\n",
        "hidden_dim_2 = 64\n",
        "code_dim = 32\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "hidden_1 = Dense(hidden_dim_1, activation='relu')(input_layer)\n",
        "dropout_1 = Dropout(0.5)(hidden_1)\n",
        "hidden_2 = Dense(hidden_dim_2, activation='relu')(dropout_1)\n",
        "dropout_2 = Dropout(0.5)(hidden_2)\n",
        "code = Dense(code_dim, activation='relu')(dropout_2)\n",
        "hidden_3 = Dense(hidden_dim_2, activation='relu')(code)\n",
        "dropout_3 = Dropout(0.5)(hidden_3)\n",
        "hidden_4 = Dense(hidden_dim_1, activation='relu')(dropout_3)\n",
        "output_layer = Dense(input_dim, activation='sigmoid')(hidden_4)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "autoencoder.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "# 데이터셋을 훈련 및 검증으로 분리\n",
        "train_data, val_data = train_test_split(TRAIN_WINDOWS.reshape(-1, input_dim), test_size=0.2, random_state=42)\n",
        "\n",
        "# 오토인코더 모델 훈련\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = autoencoder.fit(train_data, train_data,\n",
        "                          epochs=100,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True,\n",
        "                          validation_data=(val_data, val_data),\n",
        "                          verbose=1,\n",
        "                          callbacks=[early_stopping])\n",
        "\n",
        "# 훈련 과정 시각화 (옵션)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 테스트 데이터셋 예측\n",
        "TEST_WINDOWS_FLATTENED = TEST_WINDOWS.reshape(-1, input_dim)\n",
        "reconstructed = autoencoder.predict(TEST_WINDOWS_FLATTENED)\n",
        "\n",
        "# 재구성 오차 계산\n",
        "mse = np.mean(np.power(TEST_WINDOWS_FLATTENED - reconstructed, 2), axis=1)\n",
        "\n",
        "# 임계값 설정 (훈련 데이터에서의 95번째 백분위수 사용)\n",
        "threshold = np.percentile(mse, 95)\n",
        "print(f'Threshold: {threshold}')\n",
        "\n",
        "# 이상 탐지\n",
        "anomalies = mse > threshold\n",
        "anomalies = anomalies.astype(int)  # 이진형으로 변환\n",
        "\n",
        "# 결과 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(mse, label='Reconstruction Error')\n",
        "plt.hlines(threshold, xmin=0, xmax=len(mse), colors='r', label='Threshold')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 공격 레이블과 비교\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 슬라이딩 윈도우의 중앙 값을 사용하여 공격 레이블 비교\n",
        "attack_labels = ATTACK_DF.values[window_size // 2: -window_size // 2 + 1]\n",
        "\n",
        "print(confusion_matrix(attack_labels, anomalies))\n",
        "print(classification_report(attack_labels, anomalies))\n"
      ],
      "metadata": {
        "id": "QR2twL_wuPgV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}